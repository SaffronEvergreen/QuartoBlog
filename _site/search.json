[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Collections",
    "section": "",
    "text": "Logistic Regression Project 23\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nSaffron\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression Project Winter 2022\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2023\n\n\nSaffron\n\n\n\n\n\n\n  \n\n\n\n\nFirst Post\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2023\n\n\nSaffron\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nSaffron\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is under construction but is intended as a way to express what I’ve learned throughout my MPH Biostatistics program, as a student and individual who geeks out in their free time."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "I’m going to keep this as my trial and error post –\nThe content below is what was provided in the default Quarto Blog stuff\n__\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/First Blog Post/index.html",
    "href": "posts/First Blog Post/index.html",
    "title": "First Post",
    "section": "",
    "text": "This is my first attempt at posting a blog using Quarto!\nI’ve built two blogs in the past using the Blogdown-Hugo-GitHub-Netlify pipeline but those are on a laptop which has now passed over and the URL’s are nowhere to be found. So my goal here is to lay out all the fun I’ve had and the major learning curves I’ve pushed through these last few years.\nI have way too many interests and passions related and unrelated to data science so my goal is to touch on many different topics that I’ve covered in my classes, as well as what I’ve worked on outside of graduate courses.\nResume Link\nA new tool that I’ve been lightly tinkering with is typst.app which is what I’ve been using to build my resume and cover letters. Here is the link for my resume.\n\n# This is for me to edit my resume \n# https://typst.app/project/wfidmzdG33SwaQ2Adu5pNG  \n# This is for me to edit my cover letter \n# https://typst.app/project/w14mwPCsdNobGkuX_i_knB"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html",
    "href": "posts/Logistic Regression Project 22/index.html",
    "title": "Logistic Regression Project Winter 2022",
    "section": "",
    "text": "As I was rendering all of my group’s hard work, I remembered that uploading projects and assignments in full completion for all to see on the internet is against academic policy. For those looking to collaborate or hire me as part of your team, I will send a copy of the completed project upon request. To abide by the rules, I will show just a bit of the highlights and my thoughts along the way.\nThis project was done in collaboration with 3 other peers and I am forever grateful for their commitment and perseverance, especially during this final project. Please know that what I have posted below is not all my brain, it is a collaboration piece, as is most projects.\nThe datasets used in this project were sourced from the [SWAN database] (https://www.icpsr.umich.edu/web/ICPSR/series/00253)."
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#baseline-model",
    "href": "posts/Logistic Regression Project 22/index.html#baseline-model",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Baseline Model",
    "text": "Baseline Model\nRegression Formula\n\\[\\textrm{CRP} = \\beta_0 + \\beta_1 \\textrm{Financial Strain} + \\beta_2 \\textrm{Race/Ethnicity} + \\beta_3  \\textrm{Education}+ \\beta_4 \\textrm{Marital Status} + \\\\ \\beta_5 \\textrm{Smoking Status} + \\beta_6 \\textrm{Age} + \\beta_7 \\textrm{BMI} + \\beta_8 \\textrm{SBP} + \\beta_9 \\textrm{Physical Activity} + \\\\ \\beta_{10} \\textrm{Difficulty Sleeping} + \\beta_{11} \\textrm{Health Rank} + \\epsilon\\]\nBaseline Hypothesis\n\\[H_0: \\beta_{1}=\\beta_{2}=.....\\beta_{11}=0 \\quad \\text{vs.} \\quad H_A: \\text{At least one of } \\beta_{j} \\neq 0\\]\n\nWhat is blocked out: We had ran a model using lm() function and created a clean table assessing the coefficient estimates."
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#finding-outliers-using-cooks-distance",
    "href": "posts/Logistic Regression Project 22/index.html#finding-outliers-using-cooks-distance",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Finding outliers using Cook’s distance",
    "text": "Finding outliers using Cook’s distance\n\n# finding outliers \ncooks_points <- cooks.distance(baseline_model)\n\n(cooks_distance_plot <- plot(baseline_model, which = 4))\n\n\n\n\nNULL\n\n# determining outliers, regardless of influence\nas.numeric(names(cooks_points)[(cooks_points > (4/2928))]) \n\n  [1]    4   25   68   77   85   88  151  171  214  316  328  329  340  354  436\n [16]  477  482  502  503  524  535  571  576  609  657  660  672  686  727  741\n [31]  771  787  824  868  892  948  957  979  983 1020 1024 1031 1077 1113 1122\n [46] 1124 1171 1209 1262 1264 1303 1335 1341 1366 1408 1431 1449 1464 1488 1491\n [61] 1506 1550 1551 1568 1581 1592 1650 1658 1751 1775 1786 1849 1852 1859 1876\n [76] 1899 1915 1916 1922 1985 1993 2002 2040 2070 2183 2194 2317 2318 2346 2375\n [91] 2405 2428 2460 2466 2489 2514 2627 2635 2643 2727 2749 2759 2772 2796 2846\n[106] 2861 2907 2908 2913 2919 2979 2993 3043 3046 3089 3094 3108 3143 3153 3162\n[121] 3164 3212 3236 3280 3297 3300 3303\n\n  # a lot of outliers without strong influence over linearity of the model\n\n# removing influential outliers \nSWANish <-SWANish[!(row.names(SWANish) %in% c(\"3303\",\"1124\",\"1568\",\"2635\")),]\n\n\nBaseline model sans influential outliers\n\n# new model without outliers\nbaseline_model <- lm(CRP ~ Financial_Strain + Race + Education + Marital_Status + Smoke + Age + BMI + SBP + Physical_Activity + HealthRank + Difficulty_Sleeping,\n            data = SWANish)\ntidy(baseline_model) %>%  gt()\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n-8.38185665\n1.803018788\n-4.6487905\n3.487436e-06\n    Financial_Strain1\n-0.15414031\n0.206328939\n-0.7470610\n4.550870e-01\n    Race\n-0.17415986\n0.068705294\n-2.5348827\n1.130043e-02\n    Education\n-0.11889584\n0.084955353\n-1.3995097\n1.617667e-01\n    Marital_Status\n-0.17061525\n0.147686943\n-1.1552494\n2.480831e-01\n    Smoke\n0.51069935\n0.122185276\n4.1797127\n3.004750e-05\n    Age\n0.01637096\n0.034962824\n0.4682391\n6.396486e-01\n    BMI\n0.36074630\n0.015511072\n23.2573412\n6.879442e-110\n    SBP\n0.01714012\n0.005815805\n2.9471630\n3.232510e-03\n    Physical_Activity\n-0.14135195\n0.099561118\n-1.4197506\n1.557874e-01\n    HealthRank\n0.16197453\n0.108698472\n1.4901270\n1.362992e-01\n    Difficulty_Sleeping\n0.08024985\n0.082842611\n0.9687025\n3.327741e-01\n  \n  \n  \n\n\n\nregression_points <- augment(baseline_model)\n\n# baseline sans outliers \nautoplot(baseline_model)\n\n\n\n# making sure that all influential values have been removed\n  # all values below threshold   \nplot(baseline_model, which = 4)"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#transforming-variables-numeric-to-factored",
    "href": "posts/Logistic Regression Project 22/index.html#transforming-variables-numeric-to-factored",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Transforming variables: numeric to factored",
    "text": "Transforming variables: numeric to factored\nThese data transformations are for creating Table 1. It became too complicated to keep the missing values and as numeric variables. We didn’t want to significantly affect our primary dataset SWANish, so this dataset created below, swan_fct, is used as a substitute for Table 1.\n\n# remove rows with NA and create dataset for recoding variables into factors  \n\n# it's convenient to have extra datasets like this, so when edits are made to factors or variable names, it is easy to re-run without overlapping edits\n\nswan_fct <- SWANish\n\nswan_fct$Financial_Strain <- swan_fct$Financial_Strain %>% \n  factor(levels = c(\"0\", \"1\"), # how many levels set\n    labels = c(\"Somewhat/Very hard\", \n                   \"Not hard\"), \n        ordered = TRUE) # showing \"hierarchy\" primarily for creating tables and having the same structure for each\n\nswan_fct$Race <- swan_fct$Race %>% \n  factor(levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"),\n         labels = c(\"Black/African American\", \n                    \"Chinese/Chinese American\", \n                    \"Japanese/Japanese American\", \n                    \"Caucasian/White Non-Hispanic\", \n                    \"Hispanic\"), \n         ordered = TRUE)\n\nswan_fct$Education <- swan_fct$Education %>% \n  factor(levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"),\n         labels = c(\"Less than high school\", \n                    \"High school graduate\", \n                    \"Some college/technical school\", \n                    \"College graduate\", \n                    \"Post graduate education\"), \n         ordered = TRUE)\n\nswan_fct$Marital_Status <- swan_fct$Marital_Status %>% \n  factor(levels = c(\"1\", \"2\", \"3\", \"4\"), \n         labels = c(\"Single, never married\", \n                    \"Currently married/living as married\", \n                    \"Separated or divorced\", \n                    \"Widowed\"), \n         ordered = TRUE)\n\nswan_fct$Physical_Activity <- swan_fct$Physical_Activity %>% \n  factor(levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"),\n         labels = c(\"Much less than other women your age\", \n                    \"Somewhat less than other women your age\", \n                    \"About the same as other women your age\", \n                    \"Somewhat more than other women your age\", \n                    \"Much more than other women your age\"), \n         ordered = TRUE)\n\nswan_fct$HealthRank <- swan_fct$HealthRank %>% \n  factor(levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"),\n         labels = c(\"Excellent\", \n                    \"Very good\", \n                    \"Good\", \n                    \"Fair\", \n                    \"Poor\"), \n         ordered = TRUE)\n\nswan_fct$Difficulty_Sleeping <- swan_fct$Difficulty_Sleeping %>% \n  factor(levels = c(\"1\", \"2\"), \n         labels = c(\"None\", \n                    \"Yes\"),\n         ordered = TRUE) \n\nswan_fct$Smoke <- swan_fct$Smoke %>% \n  factor(levels = c(\"1\", \"2\", \"3\"), \n         labels = c(\"Never smoked\",\n                    \"Former smoker\", \n                    \"Current smoker\"),\n         ordered = TRUE)\n\n\n# check work - shows how many factor levels there are, and the amount of observations per factor level\nfct_count(swan_fct$Financial_Strain)\n\n# A tibble: 3 × 2\n  f                      n\n  <ord>              <int>\n1 Somewhat/Very hard  1967\n2 Not hard            1310\n3 <NA>                  22"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#distribution-of-crp",
    "href": "posts/Logistic Regression Project 22/index.html#distribution-of-crp",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Distribution of CRP",
    "text": "Distribution of CRP"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#boxplots",
    "href": "posts/Logistic Regression Project 22/index.html#boxplots",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Boxplots",
    "text": "Boxplots"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#density-plots",
    "href": "posts/Logistic Regression Project 22/index.html#density-plots",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Density plots",
    "text": "Density plots\n\nCheck for multicollinearity\n\n\n# any VIF value > 5 suggests multicollinearity\ncar::vif(baseline_model)\n\n   Financial_Strain                Race           Education      Marital_Status \n           1.180696            1.088712            1.195049            1.028614 \n              Smoke                 Age                 BMI                 SBP \n           1.028287            1.034975            1.292750            1.210437 \n  Physical_Activity          HealthRank Difficulty_Sleeping \n           1.259768            1.392629            1.070196"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#baseline-model-conclusion",
    "href": "posts/Logistic Regression Project 22/index.html#baseline-model-conclusion",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Baseline model conclusion",
    "text": "Baseline model conclusion\nRegression Formula\n\\[\\textrm{CRP} = \\beta_0 + \\beta_1 \\textrm{Financial Strain} + \\beta_2 \\textrm{Race/Ethnicity} + \\beta_3  \\textrm{Education}+ \\beta_4 \\textrm{Marital Status} + \\\\ \\beta_5 \\textrm{Smoking Status} + \\beta_6 \\textrm{Age} + \\beta_7 \\textrm{BMI} + \\beta_8 \\textrm{SBP} + \\beta_9 \\textrm{Physical Activity} + \\\\ \\beta_{10} \\textrm{Difficulty Sleeping} + \\beta_{11} \\textrm{Health Rank} + \\epsilon\\]\nBaseline Hypothesis\n\\[H_0: \\beta_{1}=\\beta_{2}=.....\\beta_{11}=0 \\quad \\text{vs.} \\quad H_A: \\text{At least one of } \\beta_{j} \\neq 0\\]\n\nCheck for multicollinearity\n\n\n# any VIF value > 5 suggests multicollinearity\ncar::vif(baseline_model)\n\n   Financial_Strain                Race           Education      Marital_Status \n           1.180696            1.088712            1.195049            1.028614 \n              Smoke                 Age                 BMI                 SBP \n           1.028287            1.034975            1.292750            1.210437 \n  Physical_Activity          HealthRank Difficulty_Sleeping \n           1.259768            1.392629            1.070196 \n\n\nAt this stage in the multiple linear regression analysis project, we can state there is no sign of multicollinearity and will will treat all variables as variables of interest. Below, we will determine the parsimonious (most reliable) model using Mallow’s Cp Criterion and comparing that model to what we find after determining the parsimonious model “by-hand”, which is building on, adding a new independent variable with each step."
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#forward-elimination-procedure",
    "href": "posts/Logistic Regression Project 22/index.html#forward-elimination-procedure",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Forward Elimination Procedure",
    "text": "Forward Elimination Procedure\n\nNote: The code below (with the exception of the covariates added) is solely a gift from my previous professor. \n\n# another method for determining parsimonious model\nmodel <- regsubsets(CRP ~ \n              Financial_Strain + \n              Race + Education + \n              Marital_Status + \n              Smoke + Age + BMI + \n              SBP + \n              Physical_Activity + \n              HealthRank + \n              Difficulty_Sleeping, \n                         data = SWANish, \n                         nvmax = 13,\n                    method=\"forward\")\n\np.val <- 0; i <- 1; vars_last <- NULL\n\n#----------------------------\n# do not edit code within the \"while\" loop\"\nwhile(p.val <= 0.1){\n  vars_current <- names(coef(model,i))[-1]\n  var_add <- vars_current[!vars_current %in% vars_last]\n  coef <- summary(lm(as.formula(paste(\"CRP ~ \", paste(vars_current, collapse =\" + \"), sep = \"\")),  \n                  data = SWANish))$coefficients\n  \n  p.val <- coef[var_add,\"Pr(>|t|)\"]\n  vars_last <- vars_current\n  i=i + 1\n  print(var_add) # print the variable being added \n  print(coef) #print the coefficients and p-value of new model\n}\n\n[1] \"BMI\"\n              Estimate Std. Error   t value      Pr(>|t|)\n(Intercept) -7.2246767 0.37353368 -19.34143  9.166705e-79\nBMI          0.4031809 0.01333142  30.24291 3.287630e-176\n[1] \"Smoke\"\n              Estimate Std. Error    t value      Pr(>|t|)\n(Intercept) -8.0330103  0.4167640 -19.274721  3.489860e-78\nSmoke        0.5474543  0.1189348   4.602979  4.336138e-06\nBMI          0.4012350  0.0135023  29.716055 1.620836e-170\n[1] \"SBP\"\n                Estimate  Std. Error    t value      Pr(>|t|)\n(Intercept) -10.12333941 0.656060665 -15.430493  9.249083e-52\nSmoke         0.51976089 0.119381335   4.353787  1.382613e-05\nBMI           0.38227247 0.014353787  26.632168 1.610528e-140\nSBP           0.02271891 0.005562449   4.084335  4.535400e-05\n[1] \"HealthRank\"\n                Estimate  Std. Error    t value      Pr(>|t|)\n(Intercept) -10.32713860 0.658203408 -15.689889  2.178707e-53\nSmoke         0.50692563 0.119274332   4.250082  2.201800e-05\nBMI           0.37152877 0.014769088  25.155837 6.517520e-127\nSBP           0.02122697 0.005576864   3.806256  1.438950e-04\nHealthRank    0.29529144 0.095400031   3.095297  1.984225e-03\n[1] \"Race\"\n               Estimate Std. Error    t value      Pr(>|t|)\n(Intercept) -9.37704108 0.75369495 -12.441427  1.092894e-34\nRace        -0.17371276 0.06733664  -2.579766  9.933716e-03\nSmoke        0.51630714 0.11921799   4.330782  1.534328e-05\nBMI          0.36772807 0.01482861  24.798552 1.079844e-123\nSBP          0.01856742 0.00566621   3.276868  1.061567e-03\nHealthRank   0.27865504 0.09552851   2.916983  3.560496e-03\n[1] \"Physical_Activity\"\n                     Estimate  Std. Error   t value      Pr(>|t|)\n(Intercept)       -8.54195765 0.905491077 -9.433508  7.766347e-21\nRace              -0.19359742 0.068284184 -2.835172  4.611254e-03\nSmoke              0.54688434 0.120612497  4.534226  6.011602e-06\nBMI                0.36264845 0.015437444 23.491482 5.093549e-112\nSBP                0.01687031 0.005731595  2.943388  3.271718e-03\nPhysical_Activity -0.10669600 0.099170608 -1.075883  2.820674e-01\nHealthRank         0.21552263 0.102363350  2.105467  3.533494e-02"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#summary-of-the-parsimonious-model",
    "href": "posts/Logistic Regression Project 22/index.html#summary-of-the-parsimonious-model",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Summary of the parsimonious model",
    "text": "Summary of the parsimonious model\nThe parsimonious model did not include Financial Strain, but since that is the primary predictor for this regression analysis project, we decided to include it back into the model.\nModel table\n\nWhat is blocked out: a table of the coefficient estimates from the parsimonious model using the forward elimination procedure.\n\nRegression table\n\nCheck again for multicollinearity\n\n\n# any VIF value > 5 suggests multicollinearity\ncar::vif(parsimonious_model)\n\n Financial_Strain              Race             Smoke               BMI \n         1.092213          1.083085          1.017671          1.288503 \n              SBP Physical_Activity        HealthRank \n         1.178972          1.250491          1.290492 \n\n\nThis was done prior to building the parsimonious model, but the multicollinearity test was ran again just to ensure that after removing a couple of variables, the linearity between independent variables didn’t change. All vif values are less than 5, suggesting that there is no collinearity between predictor variables in our parsimonious model."
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#concluding-model---no-interactions-just-additions",
    "href": "posts/Logistic Regression Project 22/index.html#concluding-model---no-interactions-just-additions",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Concluding Model - No interactions, just additions",
    "text": "Concluding Model - No interactions, just additions\n\\[\\textrm{CRP} = \\beta_0 + \\beta_1 \\cdot \\textrm{Financial Strain} + \\beta_2 \\cdot \\textrm{Race/Ethnicity} + \\\\ \\beta_3 \\cdot \\textrm{Education} + \\beta_4 \\cdot \\textrm{Smoking Status} + \\beta_5 \\cdot \\textrm{BMI} + \\beta_6 \\cdot \\textrm{SBP} +\\\\ \\beta_7 \\cdot \\textrm{Health Rank} + \\epsilon\\]"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#parsimonious-model-conclusion-after-testing-for-interactions",
    "href": "posts/Logistic Regression Project 22/index.html#parsimonious-model-conclusion-after-testing-for-interactions",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Parsimonious Model Conclusion: After Testing for Interactions",
    "text": "Parsimonious Model Conclusion: After Testing for Interactions\n\\[\\textrm{CRP} = \\beta_0 + \\beta_1 \\cdot \\textrm{Financial Strain} + \\beta_2 \\cdot \\textrm{Race/Ethnicity} + \\\\ \\beta_3 \\cdot \\textrm{Education} + \\beta_4 \\cdot \\textrm{Smoking Status} + \\beta_5 \\cdot \\textrm{BMI} + \\beta_6 \\cdot \\textrm{SBP} +\\\\ \\beta_7 \\cdot \\textrm{Health Rank} + \\epsilon\\]"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#testing-normality",
    "href": "posts/Logistic Regression Project 22/index.html#testing-normality",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Testing Normality",
    "text": "Testing Normality\nBelow, we are taking the residuals of the parsimonious model that we established above and looked to see if this model meets the normality assumptions.\nVisualization: Assessing Normality\nTraditional Method: Assessing Normality, Shapiro Wilkes Test\nNote: residuals are normal but there is not solid linearity (as seen in the Normal Q-Q plot) so more needs to be explored\n\nTransforming CRP\n\nNote: I decided to show the transformation of the outcome variable since that is ideally something we should have checked earlier on. I also just like how satisfying it is to see the before and after effects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy log-transforming CRP, the regression model has more normality than prior to the transformation. The Residuals vs Leverage plot indicates there’s more to look into to see if further transformations could be done. There are two continuous variables that could be possibly be transformed, which will be assessed below.\n\n\nAssessing Continuous Variables\nThere are two continuous variables in this dataset: BMI and SBP\nBMI Variable\nSBP Variable\nAfter performing log-transformations on the BMI and SBP, the density plots have shown that these variables appear more like a normal distribution."
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#packages",
    "href": "posts/Logistic Regression Project 22/index.html#packages",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(broom)\nlibrary(rstatix)\nlibrary(gt)\nlibrary(readxl)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(psych)\nlibrary(describedata) \nlibrary(ggfortify)\nlibrary(plotly)\nlibrary(GGally) \nlibrary(dplyr)\nlibrary(rsq)\nlibrary(gtsummary)\nlibrary(tinytex)\nlibrary(car)  # vif(), car::Anova()\nlibrary(cowplot)\nlibrary(moderndive)\nlibrary(forcats)\nlibrary(leaps)\nlibrary(ggridges)"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#loading-data",
    "href": "posts/Logistic Regression Project 22/index.html#loading-data",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Loading Data",
    "text": "Loading Data\n\n# baseline data\nload(\"C:/Users/mckjo/OneDrive/Desktop/GitBlog/posts/Logistic Regression Project 22/ICPSR_04368/ICPSR_04368/DS0001/04368-0001-Data.rda\")\n\n# cross-sectional data \nload(\"C:/Users/mckjo/OneDrive/Desktop/GitBlog/posts/Logistic Regression Project 22/ICPSR_28762/ICPSR_28762/DS0001/28762-0001-Data.rda\")"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#merging-datasets-renaming-variables",
    "href": "posts/Logistic Regression Project 22/index.html#merging-datasets-renaming-variables",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Merging Datasets, Renaming Variables",
    "text": "Merging Datasets, Renaming Variables"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#primary-predictor-as-binary",
    "href": "posts/Logistic Regression Project 22/index.html#primary-predictor-as-binary",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Primary Predictor as Binary",
    "text": "Primary Predictor as Binary"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#assessing-outliers-cooks-distance",
    "href": "posts/Logistic Regression Project 22/index.html#assessing-outliers-cooks-distance",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Assessing Outliers: Cook’s Distance",
    "text": "Assessing Outliers: Cook’s Distance\n\nWhat is blocked out: we performed a visual assessment to show the influential outliers using cook’s distance with the cut-off point of \\(4 \\div 2928\\) along the slope and removed the rows which had those outliers.\n\n\nBaseline Model: Reassessment\n\nWhat is blocked out: we then assessed linearity of our baseline model with the influential points removed. The assumptions for linearity were most definitely still not met at this point.\nAssumptions for linearity:\n* Linearity: nope\n* Independence: yep\n* Homoscedasticity: definitely not\n* Normality: not quite"
  },
  {
    "objectID": "posts/Logistic Regression Project 22/index.html#descriptive-statistics-table",
    "href": "posts/Logistic Regression Project 22/index.html#descriptive-statistics-table",
    "title": "Logistic Regression Project Winter 2022",
    "section": "Descriptive Statistics Table",
    "text": "Descriptive Statistics Table\n\nWhat is blocked out: a bunch of code converting the covariates to factored variables.\n\n\nTable 1\n\nNote: I was emotionally attached to this table since this was one of the learning curves I endured combining various gt libraries and functions so I’m including it since this was my baby at the time.\n\n\n# list of all variables for easy input \n\n# Financial_Strain, Race, Education, Marital_Status, Smoke, Age, BMI, SBP, Physical_Activity, HealthRank, Difficulty_Sleeping\n\nswan_fct %>% tbl_summary(\n  by = Financial_Strain, # stratifying by this binary variable (primary predictor)\n  label = list(                       # row name appearance\n    Financial_Strain ~ \"Financial Strain\",\n    Race ~ \"Race/Ethnicity\",\n    Marital_Status ~ \"Marital Status\", \n    Smoke ~ \"Smoking Status\", \n    Age ~ \"Age\",\n    BMI ~ \"Body Mass Index (BMI)\",\n    SBP ~ \"Systolic Blood Pressure (SBP)\",\n    Physical_Activity ~ \"Physical Activity\", \n    HealthRank ~ \"Health Status\", \n    Difficulty_Sleeping ~ \"Difficulty Sleeping\"\n  ),\n  include = c(     # which variables from dataset to include in table \n    Financial_Strain, Age, Race, Education, Marital_Status, SBP, Smoke, BMI, Physical_Activity, HealthRank, Difficulty_Sleeping)) %>% \n  #add_overall() %>% ## this didn't run for us\n  modify_header(label ~ \"Variable\") %>%\n  modify_footnote(\n    all_stat_cols() ~ \"Median (IQR); Frequency (%)\") %>%\n  modify_caption(\"Table 1.\") %>%\n bold_labels() %>% \n## to use gt() functions, add `as_gt()` then include gt() functions\n as_gt() %>% \n  tab_header(\n    title = \"Participants' characteristics, stratified by Financial Strain\",\n    subtitle = \"Financial Strain: How hard is it to afford basic living expenses?\") %>% \n  tab_options(heading.title.font.size = \"small\",\n              heading.title.font.weight = \"bold\",\n              heading.subtitle.font.size = \"large\",\n              heading.subtitle.font.weight = \"80\",\n              heading.align = \"right\") %>% \n  opt_table_outline(style = \"solid\", width = px(5)) %>% \n  opt_stylize(style = 6, color = \"gray\")\n\n\n\n\n\n  Table 1.\n  \n    \n      Participants' characteristics, stratified by Financial Strain\n    \n    \n      Financial Strain: How hard is it to afford basic living expenses?\n    \n    \n      Variable\n      Somewhat/Very hard, N = 1,9671\n      Not hard, N = 1,3101\n    \n  \n  \n    Age\n46.00 (44.00, 48.00)\n45.00 (43.00, 48.00)\n    Race/Ethnicity\n\n\n        Black/African American\n497 (25%)\n431 (33%)\n        Chinese/Chinese American\n180 (9.2%)\n70 (5.3%)\n        Japanese/Japanese American\n196 (10.0%)\n84 (6.4%)\n        Caucasian/White Non-Hispanic\n1,049 (53%)\n495 (38%)\n        Hispanic\n45 (2.3%)\n230 (18%)\n    Education\n\n\n        Less than high school\n45 (2.3%)\n191 (15%)\n        High school graduate\n278 (14%)\n300 (23%)\n        Some college/technical school\n594 (30%)\n454 (35%)\n        College graduate\n448 (23%)\n211 (16%)\n        Post graduate education\n594 (30%)\n143 (11%)\n        Unknown\n8\n11\n    Marital Status\n\n\n        Single, never married\n259 (13%)\n178 (14%)\n        Currently married/living as married\n1,399 (72%)\n742 (58%)\n        Separated or divorced\n265 (14%)\n327 (25%)\n        Widowed\n24 (1.2%)\n41 (3.2%)\n        Unknown\n20\n22\n    Systolic Blood Pressure (SBP)\n112 (104, 123)\n118 (108, 128)\n        Unknown\n7\n12\n    Smoking Status\n\n\n        Never smoked\n1,152 (60%)\n713 (56%)\n        Former smoker\n525 (27%)\n268 (21%)\n        Current smoker\n259 (13%)\n298 (23%)\n        Unknown\n31\n31\n    Body Mass Index (BMI)\n25 (22, 29)\n27 (23, 32)\n        Unknown\n46\n94\n    Physical Activity\n\n\n        Much less than other women your age\n60 (3.1%)\n87 (7.0%)\n        Somewhat less than other women your age\n263 (14%)\n228 (18%)\n        About the same as other women your age\n742 (39%)\n525 (42%)\n        Somewhat more than other women your age\n566 (30%)\n259 (21%)\n        Much more than other women your age\n283 (15%)\n141 (11%)\n        Unknown\n53\n70\n    Health Status\n\n\n        Excellent\n517 (27%)\n175 (14%)\n        Very good\n790 (41%)\n382 (30%)\n        Good\n481 (25%)\n464 (36%)\n        Fair\n143 (7.3%)\n223 (17%)\n        Poor\n15 (0.8%)\n46 (3.6%)\n        Unknown\n21\n20\n    Difficulty Sleeping\n\n\n        None\n1,194 (77%)\n664 (73%)\n        Yes\n362 (23%)\n245 (27%)\n        Unknown\n411\n401\n  \n  \n  \n    \n      1 Median (IQR); Frequency (%)"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html",
    "href": "posts/Logistic Regression Project 23/index.html",
    "title": "Logistic Regression Project 23",
    "section": "",
    "text": "It is against the academic policy to share the projects and content from our courses. Therefore, I have redacted a lot, and have shown the highlights of what was done.\nThis project was done in the Spring 2023 term with 2 other peers. This project is essentially the same but with more of a focus on categorical data analysis compared to ‘Logistic Regression Project 22’. This was the first project I had really felt like I had a full understanding of; there are definitely some parts that I wish I could have done more precisely but I am far more comfortable with the outcome of this model than the other.\nAs with the other logistic regression project, the data used is from the SWAN database."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#libraries-used",
    "href": "posts/Logistic Regression Project 23/index.html#libraries-used",
    "title": "Logistic Regression Project 23",
    "section": "Libraries Used",
    "text": "Libraries Used\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(skimr)\nlibrary(tidyr)\nlibrary(Hmisc)\nlibrary(ggplot2)\nlibrary(GGally)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(forcats) # for categorical variables\nlibrary(janitor) # for tables\nlibrary(gt)\nlibrary(gtable)\nlibrary(tidyverse) # data mgmt and visual\nlibrary(gtsummary)\nlibrary(broom)\nlibrary(kableExtra)\nlibrary(haven)\nlibrary(lmtest)\nlibrary(mfp)\nlibrary(ResourceSelection)\nlibrary(epiDisplay)"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#cleaning-final-dataset-df_swan",
    "href": "posts/Logistic Regression Project 23/index.html#cleaning-final-dataset-df_swan",
    "title": "Logistic Regression Project 23",
    "section": "Cleaning Final Dataset df_swan",
    "text": "Cleaning Final Dataset df_swan"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#removing-observations-with-missing-points",
    "href": "posts/Logistic Regression Project 23/index.html#removing-observations-with-missing-points",
    "title": "Logistic Regression Project 23",
    "section": "Removing Observations with Missing Points",
    "text": "Removing Observations with Missing Points"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#set-reference-levels",
    "href": "posts/Logistic Regression Project 23/index.html#set-reference-levels",
    "title": "Logistic Regression Project 23",
    "section": "Set reference levels",
    "text": "Set reference levels\n\nWhat is blocked out: I removed the coding process on how we recoded our reference levels for our covariates, but I decided to include a brief bullet point list to show what those reference levels are and why.\n\n* High Blood Pressure: No, given the majority of this sample does not have high blood pressure and we’re seeking a change in what is associated with high blood pressure.\n\nSleep Quality: Very good and fairly good categories collapsed into one reference category, since we’re assessing if poor sleep is associated with high blood pressure.\nRace: Caucasian/White Non-Hispanic due to white privilege, and systemic and institutional racism in the U.S.\nSmoking Status: No, given the majority of the sample are non-smokers.\nEducation: College Graduate and Post-Graduate given previous knowledge that at a generalized population-level, those with higher education often have better health outcomes, typically due to having more health literacy and higher income.\n\nMarital Status: Currently Married, since the majority of the population is married.\nIncome: $100,000 or more which is the highest income category, given the opportunity for better health care quality and access.\nTaking Blood Pressure Medication: Yes, given that people taking medication for high blood pressure will likely have lower blood pressure than those who are not taking any.\nQuality of Life: This was a tricky category and we ended up using the median value which was around a score of 8 out of 10. There should’ve been more research conducted to decide what our cut-off point should’ve been."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#summary-new-dataset",
    "href": "posts/Logistic Regression Project 23/index.html#summary-new-dataset",
    "title": "Logistic Regression Project 23",
    "section": "Summary new dataset",
    "text": "Summary new dataset"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#frequency-distributions",
    "href": "posts/Logistic Regression Project 23/index.html#frequency-distributions",
    "title": "Logistic Regression Project 23",
    "section": "Frequency Distributions",
    "text": "Frequency Distributions\n\nggpairs comparison"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#contigency-tables",
    "href": "posts/Logistic Regression Project 23/index.html#contigency-tables",
    "title": "Logistic Regression Project 23",
    "section": "Contigency Tables",
    "text": "Contigency Tables\n\nNote: This code below is gifted from my professor at the time. I became more familiar with lapply() throughout her course and the use of contingency tables came as a life saver, so with that note, enjoy.\n\n\n#Contingency Tables np > 5, all meet this standard, except for Hispanic, which will be excluded in further analyses due to issues within the SWAN dataset. \ndf_swan_cat <- df_swan_minusID %>% dplyr::select_if(., ~class(.) == \"factor\") \n\nlapply(df_swan_cat, function(x) table(df_swan_cat$HBP, x))\n\n$HBP\n         x\n          (1) No (2) Yes\n  (1) No    1202       0\n  (2) Yes      0     619\n\n$Sleep\n         x\n          (1) Very good (2) Fairly good (3) Fairly bad (4) Very bad\n  (1) No            319             651            195           37\n  (2) Yes           119             334            134           32\n\n$Race\n         x\n          (0) Caucasian/White Non-Hispanic (1) Black/African American\n  (1) No                               706                        193\n  (2) Yes                              244                        283\n         x\n          (2) Chinese/Chinese American (3) Japanese/Japanese American\n  (1) No                           148                            155\n  (2) Yes                           43                             49\n         x\n          (5) Hispanic\n  (1) No             0\n  (2) Yes            0\n\n$Smoking\n         x\n          (1) No (2) Yes\n  (1) No    1080     122\n  (2) Yes    533      86\n\n$Education\n         x\n          (1) Less than high school (2) High school graduate\n  (1) No                         32                      153\n  (2) Yes                        31                      124\n         x\n          (3) Some college/technical school (4) College graduate\n  (1) No                                340                  321\n  (2) Yes                               226                  105\n         x\n          (5) Post graduate education\n  (1) No                          356\n  (2) Yes                         133\n\n$Marital\n         x\n          (1) Single/never married (2) Currently married/living as married\n  (1) No                       125                                     825\n  (2) Yes                       82                                     352\n         x\n          (3) Separated (4) Widowed (5) Divorced\n  (1) No             34          47          171\n  (2) Yes            23          39          123\n\n$Income\n         x\n          (1) Less Than $19,999 (2) $20,000 to $49,999 (3) $50,000 to $99,999\n  (1) No                     74                    307                    258\n  (2) Yes                    85                    160                    146\n         x\n          (4) $100,000 or More\n  (1) No                   563\n  (2) Yes                  228\n\n$BPMed\n         x\n          (1) No (2) Yes\n  (1) No    1184      18\n  (2) Yes     49     570\n\n\nThere are sufficient cases in all cells."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-1-univariable-analysis",
    "href": "posts/Logistic Regression Project 23/index.html#step-1-univariable-analysis",
    "title": "Logistic Regression Project 23",
    "section": "Step 1 Univariable Analysis",
    "text": "Step 1 Univariable Analysis\n\nNote: I chose to show this code below since it was life changing for me. This code was also at the sole hands of my professor and I take no credit for this except for including the relevant covariates. \n\n#summarize and pull coefficients for univariate analysis for factored variables\nslr_df_swan = df_swan %>% dplyr::select(-Age, -BMI, -Caffeine, -Sleep, -HBP, -Race, -Education, -Marital, -QualLife, -Smoking, -HBP01, -SWANID, - Income, -BPMed)\n\nlapply(slr_df_swan, function(x)summary(glm(df_swan$HBP01 ~ x, family = \"binomial\"))$coefficients)\n\n$Sleep01\n              Estimate Std. Error    z value     Pr(>|z|)\n(Intercept) -0.7614039 0.05690722 -13.379743 7.942151e-41\nx1           0.3862442 0.12581464   3.069946 2.140972e-03\nx2           0.6162219 0.24802310   2.484534 1.297210e-02\n\n$Smoking01\n              Estimate Std. Error    z value     Pr(>|z|)\n(Intercept) -0.7061949 0.05293484 -13.340833 1.339535e-40\nx1           0.3565211 0.15042183   2.370142 1.778124e-02\n\n$Education01\n              Estimate Std. Error    z value     Pr(>|z|)\n(Intercept) -1.0454006 0.07535765 -13.872521 9.295206e-44\nx1           1.0136519 0.26303392   3.853693 1.163496e-04\nx2           0.8352442 0.14240520   5.865265 4.484153e-09\nx3           0.6369900 0.11421353   5.577185 2.444421e-08\n\n$Marital01\n              Estimate Std. Error    z value     Pr(>|z|)\n(Intercept) -0.8517522 0.06366338 -13.378997 8.022254e-41\nx1           0.4301577 0.15571817   2.762412 5.737604e-03\nx2           0.4608859 0.27738611   1.661532 9.660664e-02\nx3           0.6651663 0.22576680   2.946254 3.216485e-03\nx4           0.5222730 0.13427979   3.889439 1.004763e-04\n\n$Income01\n              Estimate Std. Error    z value     Pr(>|z|)\n(Intercept) -0.9039340  0.0784994 -11.515170 1.106407e-30\nx1           1.0425202  0.1773143   5.879503 4.115007e-09\nx2           0.2522601  0.1251778   2.015214 4.388223e-02\nx3           0.3345810  0.1299517   2.574657 1.003395e-02\n\n$BPMed01\n             Estimate Std. Error   z value      Pr(>|z|)\n(Intercept)  3.455265  0.2393946  14.43335  3.192144e-47\nx1          -6.640098  0.2802901 -23.69009 4.561404e-124\n\n$QualLife01\n              Estimate Std. Error   z value     Pr(>|z|)\n(Intercept) -0.5260931 0.07822327 -6.725531 1.749527e-11\nx0          -0.1967592 0.11654625 -1.688250 9.136318e-02\nx2          -0.2623643 0.12332795 -2.127371 3.338930e-02\n\n\nAll of our variables move on to the creation of a preliminary model."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-2-preliminary-variable-selection",
    "href": "posts/Logistic Regression Project 23/index.html#step-2-preliminary-variable-selection",
    "title": "Logistic Regression Project 23",
    "section": "Step 2 Preliminary Variable Selection",
    "text": "Step 2 Preliminary Variable Selection\n\nInitial Model Comparisons\nBased on the p values, our initial model would include Sleep01 (clinically significant + meets 0.25 criteria), Race (clinically significant and meets 0.05 criteria), Marital01 (meets 0.05 criteria), BMI (meets 0.05 criteria), BPMed01, (meets 0.05 criteria) and Income01 (meets 0.25 criteria) because the model with all variables is less precise at predicting hypertension in this given sample.\nHO: the beta coefficients are equal to zero\nHA: one or more beta coefficients are unequal to zero\nFor our next step, Sleep01 (clinically significant), Race (p < 0.05), Marital01 (p <0.05), BMI (p < 0.05), and BPMed01 (p < 0.05) will be retained in the next iteration of the model. The model with income will not move forward.\nFail to reject the null hypothesis. With a p-value greater than 0.05, we choose the reduced model.\nAt this point, our model is \\[logit((\\pi(HBP01| \\text{Sleep01}, \\text{Race}, \\text{Marital01} + \\text{BPMed01} + BMI)) = \\\\ \\\\beta_0 + \\beta_1 \\text{Fairly Bad Sleep} + \\beta_2 \\text{Very Bad Sleep} + \\beta_3 \\text{Black/African-American} \\\\ + \\beta_4 \\text{Chinese/Chinese-American} + \\beta_5 \\text{Japanese/Japanese-American} + \\beta_6 \\text{Single/never married} + \\beta_7 \\text{Separated} \\\\ + \\beta_8 \\text{Widowed} + \\beta_9 \\text{Divorced} + \\beta_{10} \\text{BPMed01} + \\beta_{11} \\text{BMI}\\]"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-3-assessing-change-in-coefficients-in-reduced-model",
    "href": "posts/Logistic Regression Project 23/index.html#step-3-assessing-change-in-coefficients-in-reduced-model",
    "title": "Logistic Regression Project 23",
    "section": "Step 3 Assessing Change in Coefficients in Reduced Model",
    "text": "Step 3 Assessing Change in Coefficients in Reduced Model\n\nAssessing Without ‘Income01’\nChecking for change greater than 20% in coefficients.\nThere is evidence that some confounding may be occurring due to the high percent change among two variables, therefore income should remain in the model because it is potentially a confounder."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-4-adding-excluded-variables-to-the-reduced-model",
    "href": "posts/Logistic Regression Project 23/index.html#step-4-adding-excluded-variables-to-the-reduced-model",
    "title": "Logistic Regression Project 23",
    "section": "Step 4 Adding Excluded Variables to the Reduced Model",
    "text": "Step 4 Adding Excluded Variables to the Reduced Model\n\nWhat is blocked out: For this step we ran a likelihood ratio test with the initial model as the reduced model and the initial model with the included covariate that we were assessing as the full model.\n\n\nAssessing Age\n\n\nAssessing Smoking01\n\n\nAssessing Education01\n\n\nAssessing Caffeine\n\n\nAssessing QualLife01\nNone of the initially excluded variables should be added back into the model.\n\n\nCollapse Variable Kevels\n\nAssessing binary sleep quality with our preliminary main effects model\n\n\nAssessing binary race with our preliminary main effects model\n\n\nAssessing binary marital status with our preliminary main effects model"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#preliminary-main-effects-model",
    "href": "posts/Logistic Regression Project 23/index.html#preliminary-main-effects-model",
    "title": "Logistic Regression Project 23",
    "section": "Preliminary Main Effects Model",
    "text": "Preliminary Main Effects Model"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-5-assessing-scale-for-continuous-variables",
    "href": "posts/Logistic Regression Project 23/index.html#step-5-assessing-scale-for-continuous-variables",
    "title": "Logistic Regression Project 23",
    "section": "Step 5 Assessing Scale for Continuous Variables",
    "text": "Step 5 Assessing Scale for Continuous Variables\n\nSmoothed Scatter Plots\n\n\nFractional Polynomials\n\nThis was running prior but for some reason isn’t as of this point in time of me trying to render this page. I’m keeping it in just for the sake of showing we assessed fractional polynomials.\n\n\n#fracpoly_b = mfp(HBP01~ fp(BMI, df = 4) + Age + BPMed01 + Sleep01 + Income01 + Marital01,\n#               data=df_swan, family = \"binomial\", verbose = T)\n\n#fracpoly_b$fptable\n\n#linear model works for BMI"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#main-effects-model",
    "href": "posts/Logistic Regression Project 23/index.html#main-effects-model",
    "title": "Logistic Regression Project 23",
    "section": "Main effects model",
    "text": "Main effects model\n\nModel\n\nmain.effects.model <- initial.model\n\nAfter assessing the linearity of our continuous variables, the best performing model continues to be ‘initial.model’, renamed as ‘main.effects.model’"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-6-interactions",
    "href": "posts/Logistic Regression Project 23/index.html#step-6-interactions",
    "title": "Logistic Regression Project 23",
    "section": "Step 6 Interactions",
    "text": "Step 6 Interactions\n\nNote: I have no idea how to fix this issue below. I have include and echo = FALSE but given the structure of the code (hint: it’s lapply and function but pulling stuff from the environment so it is kind of creating it’s own separate code chunk with its own set of laws I suppose).\n\n\n\n[[1]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                    1.56042    0.62781   2.485\nSleep011                                      -0.10963    0.48197  -0.227\nSleep012                                      -0.02100    1.00728  -0.021\nRace(1) Black/African American                 0.60335    0.37758   1.598\nRace(2) Chinese/Chinese American              -0.20639    0.53947  -0.383\nRace(3) Japanese/Japanese American             0.96150    0.42391   2.268\nBPMed011                                      -6.78456    0.31822 -21.320\nBMI                                            0.06239    0.02013   3.100\nIncome011                                     -0.13915    0.50819  -0.274\nIncome012                                     -0.12330    0.33666  -0.366\nIncome013                                      0.51445    0.32541   1.581\nMarital011                                    -0.96083    0.46253  -2.077\nMarital012                                    -0.29235    0.74636  -0.392\nMarital013                                    -0.66475    0.61208  -1.086\nMarital014                                    -0.18417    0.37680  -0.489\nSleep011:Race(1) Black/African American        1.37644    0.74615   1.845\nSleep012:Race(1) Black/African American        1.82494    1.21404   1.503\nSleep011:Race(2) Chinese/Chinese American      1.25486    1.16657   1.076\nSleep012:Race(2) Chinese/Chinese American    -11.85917  591.31736  -0.020\nSleep011:Race(3) Japanese/Japanese American    0.48137    1.06091   0.454\nSleep012:Race(3) Japanese/Japanese American   12.44606 1455.39799   0.009\n                                            Pr(>|z|)    \n(Intercept)                                  0.01294 *  \nSleep011                                     0.82007    \nSleep012                                     0.98337    \nRace(1) Black/African American               0.11006    \nRace(2) Chinese/Chinese American             0.70204    \nRace(3) Japanese/Japanese American           0.02332 *  \nBPMed011                                     < 2e-16 ***\nBMI                                          0.00194 ** \nIncome011                                    0.78422    \nIncome012                                    0.71418    \nIncome013                                    0.11390    \nMarital011                                   0.03777 *  \nMarital012                                   0.69528    \nMarital013                                   0.27746    \nMarital014                                   0.62501    \nSleep011:Race(1) Black/African American      0.06508 .  \nSleep012:Race(1) Black/African American      0.13279    \nSleep011:Race(2) Chinese/Chinese American    0.28207    \nSleep012:Race(2) Chinese/Chinese American    0.98400    \nSleep011:Race(3) Japanese/Japanese American  0.65002    \nSleep012:Race(3) Japanese/Japanese American  0.99318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.5  on 1820  degrees of freedom\nResidual deviance:  525.8  on 1800  degrees of freedom\nAIC: 567.8\n\nNumber of Fisher Scoring iterations: 14\n\n\n[[2]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.283439   0.619927   2.070  0.03842 *  \nSleep011                            0.786703   0.765332   1.028  0.30399    \nSleep012                           -0.037535   1.085317  -0.035  0.97241    \nRace(1) Black/African American      1.011852   0.320778   3.154  0.00161 ** \nRace(2) Chinese/Chinese American    0.007866   0.473709   0.017  0.98675    \nRace(3) Japanese/Japanese American  1.107460   0.394037   2.811  0.00495 ** \nBPMed011                           -6.692071   0.344239 -19.440  < 2e-16 ***\nBMI                                 0.064413   0.019874   3.241  0.00119 ** \nIncome011                          -0.072334   0.514299  -0.141  0.88815    \nIncome012                          -0.099978   0.332353  -0.301  0.76355    \nIncome013                           0.465729   0.323356   1.440  0.14978    \nMarital011                         -0.956631   0.468640  -2.041  0.04122 *  \nMarital012                         -0.252366   0.757010  -0.333  0.73885    \nMarital013                         -0.693576   0.610387  -1.136  0.25584    \nMarital014                         -0.179125   0.373172  -0.480  0.63122    \nSleep011:BPMed011                  -0.395966   0.855614  -0.463  0.64352    \nSleep012:BPMed011                   1.180241   1.213732   0.972  0.33085    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  531.03  on 1804  degrees of freedom\nAIC: 565.03\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[3]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.4309101  0.7418752   1.929  0.05376 .  \nSleep011                            0.0344342  1.1824329   0.029  0.97677    \nSleep012                            0.9843446  2.0459917   0.481  0.63044    \nRace(1) Black/African American      1.0313280  0.3205687   3.217  0.00129 ** \nRace(2) Chinese/Chinese American    0.0114880  0.4730464   0.024  0.98063    \nRace(3) Japanese/Japanese American  1.1035742  0.3936501   2.803  0.00506 ** \nBPMed011                           -6.7155294  0.3129457 -21.459  < 2e-16 ***\nBMI                                 0.0595600  0.0249609   2.386  0.01703 *  \nIncome011                          -0.1029611  0.5192188  -0.198  0.84281    \nIncome012                          -0.1147497  0.3327172  -0.345  0.73018    \nIncome013                           0.4743448  0.3223023   1.472  0.14109    \nMarital011                         -0.9910955  0.4704926  -2.107  0.03516 *  \nMarital012                         -0.2706109  0.7497872  -0.361  0.71816    \nMarital013                         -0.6618042  0.6123452  -1.081  0.27980    \nMarital014                         -0.1819259  0.3727933  -0.488  0.62554    \nSleep011:BMI                        0.0154446  0.0400876   0.385  0.70004    \nSleep012:BMI                        0.0003948  0.0660636   0.006  0.99523    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  531.97  on 1804  degrees of freedom\nAIC: 565.97\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[4]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.14122    0.62595   1.823  0.06828 .  \nSleep011                            0.87988    0.49410   1.781  0.07495 .  \nSleep012                            1.54734    0.82887   1.867  0.06193 .  \nRace(1) Black/African American      1.02999    0.32125   3.206  0.00135 ** \nRace(2) Chinese/Chinese American    0.01377    0.47207   0.029  0.97672    \nRace(3) Japanese/Japanese American  1.13423    0.39309   2.885  0.00391 ** \nBPMed011                           -6.72042    0.31329 -21.451  < 2e-16 ***\nBMI                                 0.06571    0.02018   3.256  0.00113 ** \nIncome011                           0.14579    0.63536   0.229  0.81852    \nIncome012                           0.17013    0.37766   0.450  0.65235    \nIncome013                           0.56681    0.37665   1.505  0.13236    \nMarital011                         -0.98891    0.47239  -2.093  0.03631 *  \nMarital012                         -0.27791    0.74356  -0.374  0.70858    \nMarital013                         -0.64259    0.62098  -1.035  0.30076    \nMarital014                         -0.13161    0.37549  -0.350  0.72597    \nSleep011:Income011                 -0.42898    1.10299  -0.389  0.69733    \nSleep012:Income011                 -1.66471    1.67488  -0.994  0.32026    \nSleep011:Income012                 -1.07495    0.84152  -1.277  0.20147    \nSleep012:Income012                 -1.71441    1.69364  -1.012  0.31141    \nSleep011:Income013                 -0.44914    0.82911  -0.542  0.58801    \nSleep012:Income013                 -0.22559    1.18940  -0.190  0.84957    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  528.84  on 1800  degrees of freedom\nAIC: 570.84\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[5]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients: (1 not defined because of singularities)\n                                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                          1.35617    0.62068   2.185  0.02889 *  \nSleep011                             0.40093    0.41468   0.967  0.33363    \nSleep012                             1.36569    0.60866   2.244  0.02485 *  \nRace(1) Black/African American       1.03074    0.32136   3.207  0.00134 ** \nRace(2) Chinese/Chinese American     0.01987    0.47081   0.042  0.96634    \nRace(3) Japanese/Japanese American   1.10420    0.39440   2.800  0.00511 ** \nBPMed011                            -6.72736    0.31459 -21.384  < 2e-16 ***\nBMI                                  0.06168    0.02010   3.069  0.00215 ** \nIncome011                           -0.01202    0.53155  -0.023  0.98195    \nIncome012                           -0.06614    0.33268  -0.199  0.84242    \nIncome013                            0.47009    0.32250   1.458  0.14494    \nMarital011                          -1.17576    0.54071  -2.174  0.02967 *  \nMarital012                          -0.66047    0.93076  -0.710  0.47795    \nMarital013                          -0.52086    0.69144  -0.753  0.45127    \nMarital014                           0.01153    0.42207   0.027  0.97821    \nSleep011:Marital011                  0.89502    1.04748   0.854  0.39286    \nSleep012:Marital011                 -0.35902    1.68035  -0.214  0.83081    \nSleep011:Marital012                  1.13744    1.45092   0.784  0.43307    \nSleep012:Marital012                       NA         NA      NA       NA    \nSleep011:Marital013                 -0.26598    1.71142  -0.155  0.87649    \nSleep012:Marital013                -13.54186  709.56262  -0.019  0.98477    \nSleep011:Marital014                 -0.43770    0.91037  -0.481  0.63067    \nSleep012:Marital014                 -2.22310    1.96595  -1.131  0.25814    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  528.29  on 1799  degrees of freedom\nAIC: 572.29\n\nNumber of Fisher Scoring iterations: 14\n\n\n[[6]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                             Estimate Std. Error z value\n(Intercept)                                   1.25868    0.62657   2.009\nSleep011                                      0.45799    0.32679   1.402\nSleep012                                      0.95832    0.53998   1.775\nRace(1) Black/African American                0.85423    0.53112   1.608\nRace(2) Chinese/Chinese American              1.04538    1.06584   0.981\nRace(3) Japanese/Japanese American           14.75406  616.10033   0.024\nBPMed011                                     -6.57544    0.39848 -16.501\nBMI                                           0.06246    0.01955   3.195\nIncome011                                    -0.05439    0.50587  -0.108\nIncome012                                    -0.11552    0.33194  -0.348\nIncome013                                     0.48715    0.32410   1.503\nMarital011                                   -0.98460    0.46451  -2.120\nMarital012                                   -0.30817    0.74049  -0.416\nMarital013                                   -0.67766    0.60189  -1.126\nMarital014                                   -0.17412    0.36773  -0.474\nRace(1) Black/African American:BPMed011       0.22512    0.62517   0.360\nRace(2) Chinese/Chinese American:BPMed011    -1.63565    1.30190  -1.256\nRace(3) Japanese/Japanese American:BPMed011 -13.78653  616.10047  -0.022\n                                            Pr(>|z|)    \n(Intercept)                                   0.0446 *  \nSleep011                                      0.1611    \nSleep012                                      0.0759 .  \nRace(1) Black/African American                0.1078    \nRace(2) Chinese/Chinese American              0.3267    \nRace(3) Japanese/Japanese American            0.9809    \nBPMed011                                      <2e-16 ***\nBMI                                           0.0014 ** \nIncome011                                     0.9144    \nIncome012                                     0.7278    \nIncome013                                     0.1328    \nMarital011                                    0.0340 *  \nMarital012                                    0.6773    \nMarital013                                    0.2602    \nMarital014                                    0.6359    \nRace(1) Black/African American:BPMed011       0.7188    \nRace(2) Chinese/Chinese American:BPMed011     0.2090    \nRace(3) Japanese/Japanese American:BPMed011   0.9821    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  528.04  on 1803  degrees of freedom\nAIC: 564.04\n\nNumber of Fisher Scoring iterations: 16\n\n\n[[7]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                       Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                             1.37585    0.85012   1.618  0.10557    \nSleep011                                0.44089    0.33045   1.334  0.18214    \nSleep012                                1.02068    0.54156   1.885  0.05947 .  \nRace(1) Black/African American          1.66642    1.27444   1.308  0.19102    \nRace(2) Chinese/Chinese American       -6.26118    2.40784  -2.600  0.00931 ** \nRace(3) Japanese/Japanese American      1.79959    2.38999   0.753  0.45147    \nBPMed011                               -6.77650    0.32005 -21.173  < 2e-16 ***\nBMI                                     0.06259    0.02918   2.145  0.03195 *  \nIncome011                              -0.04964    0.52346  -0.095  0.92445    \nIncome012                              -0.09452    0.33537  -0.282  0.77807    \nIncome013                               0.49735    0.32564   1.527  0.12669    \nMarital011                             -0.96841    0.47975  -2.019  0.04353 *  \nMarital012                             -0.22154    0.73639  -0.301  0.76353    \nMarital013                             -0.68280    0.62815  -1.087  0.27704    \nMarital014                             -0.16290    0.37653  -0.433  0.66528    \nRace(1) Black/African American:BMI     -0.02091    0.04231  -0.494  0.62111    \nRace(2) Chinese/Chinese American:BMI    0.26223    0.09681   2.709  0.00675 ** \nRace(3) Japanese/Japanese American:BMI -0.02952    0.10127  -0.292  0.77065    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  522.74  on 1803  degrees of freedom\nAIC: 558.74\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[8]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                             Estimate Std. Error z value\n(Intercept)                                   1.30106    0.62418   2.084\nSleep011                                      0.50344    0.32978   1.527\nSleep012                                      0.98297    0.54702   1.797\nRace(1) Black/African American                1.16812    0.53399   2.188\nRace(2) Chinese/Chinese American              0.69325    0.64116   1.081\nRace(3) Japanese/Japanese American            0.45906    0.65119   0.705\nBPMed011                                     -6.77442    0.31947 -21.205\nBMI                                           0.06531    0.01992   3.278\nIncome011                                    -0.62625    0.83636  -0.749\nIncome012                                     0.07351    0.47983   0.153\nIncome013                                     0.40344    0.48997   0.823\nMarital011                                   -0.95487    0.46734  -2.043\nMarital012                                   -0.32005    0.75877  -0.422\nMarital013                                   -0.70153    0.60049  -1.168\nMarital014                                   -0.13334    0.37929  -0.352\nRace(1) Black/African American:Income011      0.64942    1.06662   0.609\nRace(2) Chinese/Chinese American:Income011    0.43473    2.20175   0.197\nRace(3) Japanese/Japanese American:Income011 -0.11530    3.25302  -0.035\nRace(1) Black/African American:Income012     -0.70536    0.79130  -0.891\nRace(2) Chinese/Chinese American:Income012   -1.62690    1.18703  -1.371\nRace(3) Japanese/Japanese American:Income012  1.02195    0.94502   1.081\nRace(1) Black/African American:Income013     -0.01481    0.78351  -0.019\nRace(2) Chinese/Chinese American:Income013   -1.38165    1.17284  -1.178\nRace(3) Japanese/Japanese American:Income013  1.19847    0.92406   1.297\n                                             Pr(>|z|)    \n(Intercept)                                   0.03712 *  \nSleep011                                      0.12687    \nSleep012                                      0.07234 .  \nRace(1) Black/African American                0.02870 *  \nRace(2) Chinese/Chinese American              0.27959    \nRace(3) Japanese/Japanese American            0.48084    \nBPMed011                                      < 2e-16 ***\nBMI                                           0.00105 ** \nIncome011                                     0.45399    \nIncome012                                     0.87824    \nIncome013                                     0.41028    \nMarital011                                    0.04103 *  \nMarital012                                    0.67317    \nMarital013                                    0.24271    \nMarital014                                    0.72518    \nRace(1) Black/African American:Income011      0.54261    \nRace(2) Chinese/Chinese American:Income011    0.84348    \nRace(3) Japanese/Japanese American:Income011  0.97173    \nRace(1) Black/African American:Income012      0.37272    \nRace(2) Chinese/Chinese American:Income012    0.17051    \nRace(3) Japanese/Japanese American:Income012  0.27952    \nRace(1) Black/African American:Income013      0.98492    \nRace(2) Chinese/Chinese American:Income013    0.23878    \nRace(3) Japanese/Japanese American:Income013  0.19464    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  524.33  on 1797  degrees of freedom\nAIC: 572.33\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[9]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                    1.36437    0.61438   2.221\nSleep011                                       0.44482    0.33024   1.347\nSleep012                                       0.99189    0.54449   1.822\nRace(1) Black/African American                 0.94419    0.42391   2.227\nRace(2) Chinese/Chinese American               0.12708    0.53506   0.238\nRace(3) Japanese/Japanese American             0.98285    0.44387   2.214\nBPMed011                                      -6.76753    0.32034 -21.126\nBMI                                            0.06444    0.01981   3.253\nIncome011                                     -0.13782    0.53275  -0.259\nIncome012                                     -0.09609    0.33547  -0.286\nIncome013                                      0.49708    0.32392   1.535\nMarital011                                    -0.97043    0.69881  -1.389\nMarital012                                    -0.82210    1.64310  -0.500\nMarital013                                    -1.29979    0.96144  -1.352\nMarital014                                    -0.21428    0.58087  -0.369\nRace(1) Black/African American:Marital011      0.22114    0.96109   0.230\nRace(2) Chinese/Chinese American:Marital011   -1.44056    1.45729  -0.989\nRace(3) Japanese/Japanese American:Marital011  0.07479    1.98187   0.038\nRace(1) Black/African American:Marital012      0.77441    1.89299   0.409\nRace(2) Chinese/Chinese American:Marital012    0.69836    3.31944   0.210\nRace(3) Japanese/Japanese American:Marital012  0.47673    3.83073   0.124\nRace(1) Black/African American:Marital013      0.43212    1.30390   0.331\nRace(2) Chinese/Chinese American:Marital013    1.29374    2.26170   0.572\nRace(3) Japanese/Japanese American:Marital013  2.16745    1.50353   1.442\nRace(1) Black/African American:Marital014      0.12267    0.82102   0.149\nRace(2) Chinese/Chinese American:Marital014   -0.44326    1.62551  -0.273\nRace(3) Japanese/Japanese American:Marital014  0.20135    1.20515   0.167\n                                              Pr(>|z|)    \n(Intercept)                                    0.02637 *  \nSleep011                                       0.17799    \nSleep012                                       0.06850 .  \nRace(1) Black/African American                 0.02593 *  \nRace(2) Chinese/Chinese American               0.81226    \nRace(3) Japanese/Japanese American             0.02681 *  \nBPMed011                                       < 2e-16 ***\nBMI                                            0.00114 ** \nIncome011                                      0.79586    \nIncome012                                      0.77455    \nIncome013                                      0.12489    \nMarital011                                     0.16493    \nMarital012                                     0.61684    \nMarital013                                     0.17640    \nMarital014                                     0.71220    \nRace(1) Black/African American:Marital011      0.81802    \nRace(2) Chinese/Chinese American:Marital011    0.32290    \nRace(3) Japanese/Japanese American:Marital011  0.96990    \nRace(1) Black/African American:Marital012      0.68247    \nRace(2) Chinese/Chinese American:Marital012    0.83337    \nRace(3) Japanese/Japanese American:Marital012  0.90096    \nRace(1) Black/African American:Marital013      0.74034    \nRace(2) Chinese/Chinese American:Marital013    0.56731    \nRace(3) Japanese/Japanese American:Marital013  0.14942    \nRace(1) Black/African American:Marital014      0.88123    \nRace(2) Chinese/Chinese American:Marital014    0.78509    \nRace(3) Japanese/Japanese American:Marital014  0.86731    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  528.74  on 1794  degrees of freedom\nAIC: 582.74\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[10]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         2.64505    1.05770   2.501  0.01239 *  \nSleep011                            0.44389    0.32776   1.354  0.17563    \nSleep012                            0.95084    0.54138   1.756  0.07903 .  \nRace(1) Black/African American      0.99884    0.31618   3.159  0.00158 ** \nRace(2) Chinese/Chinese American   -0.01643    0.49578  -0.033  0.97357    \nRace(3) Japanese/Japanese American  1.15556    0.40064   2.884  0.00392 ** \nBPMed011                           -8.46216    1.19238  -7.097 1.28e-12 ***\nBMI                                 0.01637    0.03503   0.467  0.64020    \nIncome011                          -0.04911    0.50423  -0.097  0.92242    \nIncome012                          -0.10908    0.33386  -0.327  0.74387    \nIncome013                           0.48649    0.32368   1.503  0.13285    \nMarital011                         -0.95338    0.46085  -2.069  0.03857 *  \nMarital012                         -0.26923    0.75379  -0.357  0.72096    \nMarital013                         -0.68278    0.60243  -1.133  0.25705    \nMarital014                         -0.16046    0.37106  -0.432  0.66543    \nBPMed011:BMI                        0.06243    0.03976   1.570  0.11632    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  529.84  on 1805  degrees of freedom\nAIC: 561.84\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[11]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.38591    0.65908   2.103  0.03549 *  \nSleep011                            0.43284    0.32840   1.318  0.18750    \nSleep012                            0.91839    0.52841   1.738  0.08221 .  \nRace(1) Black/African American      1.03819    0.31911   3.253  0.00114 ** \nRace(2) Chinese/Chinese American    0.03094    0.48296   0.064  0.94892    \nRace(3) Japanese/Japanese American  1.12533    0.39829   2.825  0.00472 ** \nBPMed011                           -6.79080    0.46714 -14.537  < 2e-16 ***\nBMI                                 0.06348    0.01958   3.242  0.00119 ** \nIncome011                          -0.90032    0.63782  -1.412  0.15808    \nIncome012                          -0.02766    0.61065  -0.045  0.96387    \nIncome013                           1.34348    1.07870   1.245  0.21296    \nMarital011                         -0.99234    0.46327  -2.142  0.03219 *  \nMarital012                         -0.35328    0.72832  -0.485  0.62763    \nMarital013                         -0.71560    0.59516  -1.202  0.22922    \nMarital014                         -0.20351    0.37315  -0.545  0.58549    \nBPMed011:Income011                  1.49964    0.79301   1.891  0.05862 .  \nBPMed011:Income012                 -0.12341    0.73188  -0.169  0.86610    \nBPMed011:Income013                 -0.95115    1.13915  -0.835  0.40373    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  526.64  on 1803  degrees of freedom\nAIC: 562.64\n\nNumber of Fisher Scoring iterations: 7\n\n\n[[12]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                          1.190253   0.630297   1.888  0.05897 .  \nSleep011                             0.476017   0.326834   1.456  0.14527    \nSleep012                             0.983765   0.539665   1.823  0.06832 .  \nRace(1) Black/African American       1.031145   0.322105   3.201  0.00137 ** \nRace(2) Chinese/Chinese American     0.009365   0.470194   0.020  0.98411    \nRace(3) Japanese/Japanese American   1.095500   0.392249   2.793  0.00522 ** \nBPMed011                            -6.586487   0.382266 -17.230  < 2e-16 ***\nBMI                                  0.064660   0.019886   3.252  0.00115 ** \nIncome011                           -0.065775   0.531515  -0.124  0.90151    \nIncome012                           -0.110428   0.332671  -0.332  0.73993    \nIncome013                            0.479812   0.321167   1.494  0.13518    \nMarital011                          -0.925456   0.633058  -1.462  0.14377    \nMarital012                          12.703182 496.312880   0.026  0.97958    \nMarital013                          -0.056510   1.075610  -0.053  0.95810    \nMarital014                          -0.182469   0.685690  -0.266  0.79015    \nBPMed011:Marital011                 -0.064857   0.881572  -0.074  0.94135    \nBPMed011:Marital012                -13.480348 496.313962  -0.027  0.97833    \nBPMed011:Marital013                 -1.180383   1.489617  -0.792  0.42812    \nBPMed011:Marital014                  0.006055   0.788735   0.008  0.99387    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  529.94  on 1802  degrees of freedom\nAIC: 567.94\n\nNumber of Fisher Scoring iterations: 15\n\n\n[[13]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         0.315583   0.887546   0.356  0.72216    \nSleep011                            0.502386   0.331118   1.517  0.12921    \nSleep012                            0.972887   0.549682   1.770  0.07674 .  \nRace(1) Black/African American      1.024278   0.323054   3.171  0.00152 ** \nRace(2) Chinese/Chinese American    0.002979   0.464039   0.006  0.99488    \nRace(3) Japanese/Japanese American  1.125004   0.396413   2.838  0.00454 ** \nBPMed011                           -6.762386   0.317151 -21.322  < 2e-16 ***\nBMI                                 0.102477   0.031199   3.285  0.00102 ** \nIncome011                           0.498585   1.818145   0.274  0.78391    \nIncome012                           0.983624   1.333666   0.738  0.46080    \nIncome013                           3.196710   1.376198   2.323  0.02019 *  \nMarital011                         -0.988340   0.472232  -2.093  0.03636 *  \nMarital012                         -0.270663   0.748400  -0.362  0.71761    \nMarital013                         -0.650182   0.611307  -1.064  0.28751    \nMarital014                         -0.203199   0.374672  -0.542  0.58758    \nBMI:Income011                      -0.024693   0.057232  -0.431  0.66613    \nBMI:Income012                      -0.041067   0.047155  -0.871  0.38381    \nBMI:Income013                      -0.100878   0.049944  -2.020  0.04340 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  527.84  on 1803  degrees of freedom\nAIC: 563.84\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[14]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.58211    0.78338   2.020  0.04342 *  \nSleep011                            0.45483    0.32711   1.390  0.16439    \nSleep012                            1.03466    0.54228   1.908  0.05639 .  \nRace(1) Black/African American      1.01710    0.32155   3.163  0.00156 ** \nRace(2) Chinese/Chinese American   -0.01606    0.47346  -0.034  0.97294    \nRace(3) Japanese/Japanese American  1.07766    0.39358   2.738  0.00618 ** \nBPMed011                           -6.72695    0.31484 -21.366  < 2e-16 ***\nBMI                                 0.05421    0.02678   2.024  0.04294 *  \nIncome011                          -0.11705    0.52422  -0.223  0.82332    \nIncome012                          -0.09297    0.33308  -0.279  0.78015    \nIncome013                           0.48777    0.32365   1.507  0.13179    \nMarital011                         -2.25854    1.50172  -1.504  0.13259    \nMarital012                          0.56140    3.15687   0.178  0.85885    \nMarital013                          0.46822    2.72212   0.172  0.86343    \nMarital014                         -0.71324    1.43534  -0.497  0.61925    \nBMI:Marital011                      0.04221    0.04745   0.890  0.37370    \nBMI:Marital012                     -0.02920    0.11336  -0.258  0.79670    \nBMI:Marital013                     -0.03867    0.09290  -0.416  0.67718    \nBMI:Marital014                      0.01944    0.04941   0.393  0.69405    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  530.85  on 1802  degrees of freedom\nAIC: 568.85\n\nNumber of Fisher Scoring iterations: 6\n\n\n[[15]]\n\nCall:\nglm(formula = reformulate(c(vars, cb), \"HBP01\", env = .env), \n    family = binomial, data = df_swan)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                         1.469764   0.631645   2.327  0.01997 *  \nSleep011                            0.451884   0.331023   1.365  0.17222    \nSleep012                            1.025742   0.550423   1.864  0.06238 .  \nRace(1) Black/African American      1.010216   0.321705   3.140  0.00169 ** \nRace(2) Chinese/Chinese American    0.003417   0.479237   0.007  0.99431    \nRace(3) Japanese/Japanese American  1.113929   0.394628   2.823  0.00476 ** \nBPMed011                           -6.840611   0.330909 -20.672  < 2e-16 ***\nBMI                                 0.061862   0.020035   3.088  0.00202 ** \nIncome011                           0.644566   0.952429   0.677  0.49856    \nIncome012                          -0.207287   0.421030  -0.492  0.62248    \nIncome013                           0.483421   0.378291   1.278  0.20128    \nMarital011                         -0.835400   0.981333  -0.851  0.39461    \nMarital012                         -0.770281   1.387083  -0.555  0.57867    \nMarital013                         -1.391565   0.958184  -1.452  0.14642    \nMarital014                          0.044020   0.632396   0.070  0.94451    \nIncome011:Marital011               -0.247593   1.534024  -0.161  0.87178    \nIncome012:Marital011               -0.449977   1.231241  -0.365  0.71476    \nIncome013:Marital011               -0.708678   1.404843  -0.504  0.61394    \nIncome011:Marital012               -0.921711   2.285121  -0.403  0.68669    \nIncome012:Marital012                0.776991   2.225427   0.349  0.72698    \nIncome013:Marital012                1.339378   1.776618   0.754  0.45091    \nIncome011:Marital013               -0.106891   1.796217  -0.060  0.95255    \nIncome012:Marital013                0.668799   1.541345   0.434  0.66436    \nIncome013:Marital013                1.856966   1.435691   1.293  0.19586    \nIncome011:Marital014               -1.929189   1.371690  -1.406  0.15960    \nIncome012:Marital014                0.339140   0.891680   0.380  0.70369    \nIncome013:Marital014               -0.552293   1.013895  -0.545  0.58594    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2334.47  on 1820  degrees of freedom\nResidual deviance:  525.28  on 1794  degrees of freedom\nAIC: 579.28\n\nNumber of Fisher Scoring iterations: 6\n\n\nThere are no significant interactions present between the levels of Sleep01 and other variables included in our main effects model at the alpha = 0.05 level."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#preliminary-final-model",
    "href": "posts/Logistic Regression Project 23/index.html#preliminary-final-model",
    "title": "Logistic Regression Project 23",
    "section": "Preliminary Final Model",
    "text": "Preliminary Final Model\n\nModel\nAfter assessing the linearity of our continuous variables, the best performing model continues to be ‘main.effects.model’"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#step-7-addressing-issues-and-assessing-model-fit",
    "href": "posts/Logistic Regression Project 23/index.html#step-7-addressing-issues-and-assessing-model-fit",
    "title": "Logistic Regression Project 23",
    "section": "Step 7 Addressing Issues and Assessing Model Fit",
    "text": "Step 7 Addressing Issues and Assessing Model Fit\n\nVIF\n\nlibrary(car)\ncar::vif(main.effects.model)\n\n              GVIF Df GVIF^(1/(2*Df))\nSleep01   1.099543  2        1.024007\nRace      1.432084  3        1.061683\nMarital01 1.374184  4        1.040532\nBMI       1.238386  1        1.112828\nBPMed01   1.208420  1        1.099282\nIncome01  1.269470  3        1.040568\n\n\nThere does not appear to be an issue with colinearity.\n\n\nPearson Goodness of Fit\nWe do not use Pearson Goodness of fit due to the continuous BMI Variable.\n\n\nHosmer Lemeshow Goodness of Fit\nCovariate pattern is greater than six due to the existence of a continuous variable in the model.\n\\(H_0:\\) the model fits the data well\n\\(H_A:\\) the model does not fit the data well\nConclusion: Fail to reject null hypothesis. Thus, the selected model for SWAN dataset fits the data relatively well.\n\n\nROC Curve and AUC\nTo quantify how well our model predicts a binary outcome.\n\n\n\n\n\nOur ROC is quite good, 0.973 is excellent, perhaps excessively so for a class project model using real-world data.\n\n\nAIC and BIC\nThe AIC and BIC are equivalent between the two models, 557.47/601.52, meaning they are comparable.\n\n\nVisual Logistic Diagnostics\n\nCharts\n\nsource(\"Logistic_Dx_Functions.R\") \n\nPlot the change in standardized deviance residuals against the estimated/predicted probabilities.\nPlot the change in coefficient estimates against the estimated/predicted probabilities.\n\n\nDiagnostic points\nThe AIC and BIC are very small when influential points are excluded, so it is likely the model is over fit when the influential points are removed.\nThe ROC and AUC are comparable to that of the preliminary final model."
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#estimated-logistic-regression-equation",
    "href": "posts/Logistic Regression Project 23/index.html#estimated-logistic-regression-equation",
    "title": "Logistic Regression Project 23",
    "section": "Estimated Logistic Regression Equation",
    "text": "Estimated Logistic Regression Equation\nWith covariates included \\[logit((\\hat{\\pi}(HBP01| \\text{Sleep01}, \\text{Race}, \\text{Marital01} + \\text{BPMed01} + BMI + \\text{Income01})) = \\\\ 1.29180 + 0.47144 \\cdot \\text{Fairly Bad Sleep} + 0.97776 \\cdot \\text{Very Bad Sleep} + 1.02938 \\cdot \\text{Black/African-American} \\\\ + 0.02416 \\cdot \\text{Chinese/Chinese-American} + 1.10728 \\cdot \\text{Japanese/Japanese-American} - 0.98783 \\cdot \\text{Single/never married} \\\\ - 0.26615 \\cdot \\text{Separated} - 0.6754 \\cdot \\text{Widowed} - -0.18008 \\cdot \\text{Divorced} - 6.70745 \\cdot \\text{BPMed01} + 0.06436 \\cdot \\text{BMI} \\\\ +  - 0.08290 \\cdot \\text {Annual Income}<19,999 - 0.10850 \\cdot \\text{Annual Income}20-49,999 + 0.47616 \\cdot \\text{Annual Income}50-99,999\\]"
  },
  {
    "objectID": "posts/Logistic Regression Project 23/index.html#odds-ratio-tables",
    "href": "posts/Logistic Regression Project 23/index.html#odds-ratio-tables",
    "title": "Logistic Regression Project 23",
    "section": "Odds Ratio Tables",
    "text": "Odds Ratio Tables\n\ntable2\n\n\n\n \n  \n      \n    Crude OR \n    Adjusted OR \n    P-value (Wald's Test) \n    P-value (LR Test \n  \n \n\n  \n    Sleep01..ref..0 \n     \n     \n     \n    0.109 \n  \n  \n    X...1 \n    1.47 (1.15,1.88) \n    1.6 (0.85,3.04) \n    0.149 \n     \n  \n  \n    X...2 \n    1.85 (1.14,3.01) \n    2.66 (0.92,7.65) \n    0.07 \n     \n  \n  \n    X \n     \n     \n     \n     \n  \n  \n    Race..ref...0..Caucasian.White.Non.Hispanic \n     \n     \n     \n    0.001 \n  \n  \n    X....1..Black.African.American \n    4.24 (3.36,5.36) \n    2.8 (1.49,5.25) \n    0.001 \n     \n  \n  \n    X....2..Chinese.Chinese.American \n    0.84 (0.58,1.22) \n    1.02 (0.41,2.58) \n    0.959 \n     \n  \n  \n    X....3..Japanese.Japanese.American \n    0.91 (0.64,1.3) \n    3.03 (1.4,6.53) \n    0.005 \n     \n  \n  \n    X.1 \n     \n     \n     \n     \n  \n  \n    Marital01..ref..0 \n     \n     \n     \n    0.265 \n  \n  \n    X...1.1 \n    1.54 (1.13,2.09) \n    0.37 (0.15,0.94) \n    0.035 \n     \n  \n  \n    X...2.1 \n    1.59 (0.92,2.73) \n    0.77 (0.18,3.33) \n    0.722 \n     \n  \n  \n    X...3 \n    1.94 (1.25,3.03) \n    0.51 (0.15,1.68) \n    0.267 \n     \n  \n  \n    X...4 \n    1.69 (1.3,2.19) \n    0.84 (0.4,1.73) \n    0.628 \n     \n  \n  \n    X.2 \n     \n     \n     \n     \n  \n  \n    BMI..cont..var.. \n    1.13 (1.11,1.15) \n    1.07 (1.03,1.11) \n    0.001 \n    0.002 \n  \n  \n    X.3 \n     \n     \n     \n     \n  \n  \n    BPMed01..1.vs.0 \n    0 (0,0) \n    0 (0,0) \n    < 0.001 \n    < 0.001 \n  \n  \n    X.4 \n     \n     \n     \n     \n  \n  \n    Income01..ref..0 \n     \n     \n     \n    0.362 \n  \n  \n    X...1.2 \n    2.84 (2,4.02) \n    0.92 (0.33,2.54) \n    0.873 \n     \n  \n  \n    X...2.2 \n    1.29 (1.01,1.64) \n    0.9 (0.47,1.72) \n    0.743 \n     \n  \n  \n    X...3.1 \n    1.4 (1.08,1.8) \n    1.61 (0.86,3.03) \n    0.139 \n     \n  \n  \n    X.5"
  }
]